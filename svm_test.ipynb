{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hate Speech Filtering\n",
    "\n",
    "Using Tf-Idf and BoW to build SVM model\n",
    "\n",
    "Linear model? Or RBF model?\n",
    "\n",
    "RACIST texts classified with '1'\n",
    "NON-RACIST texts classified with '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "# Web scraper libraries\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import csv\n",
    "\n",
    "# NLTK\n",
    "import re \n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# ML libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "# import matplotlib.pyplot as plt\n",
    "logReg = LogisticRegression()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 100.0.4896\n",
      "Get LATEST chromedriver version for 100.0.4896 google-chrome\n",
      "Driver [/Users/tonycui/.wdm/drivers/chromedriver/mac64_m1/100.0.4896.60/chromedriver] found in cache\n",
      "/var/folders/y0/sry46qbs59n25vtlyr3vfqrh0000gn/T/ipykernel_11884/1559815854.py:28: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=ChromeDriverManager().install(), options=options)\n",
      "/var/folders/y0/sry46qbs59n25vtlyr3vfqrh0000gn/T/ipykernel_11884/1559815854.py:3: DeprecationWarning: find_elements_by_tag_name is deprecated. Please use find_elements(by=By.TAG_NAME, value=name) instead\n",
      "  a_tags = driver.find_elements_by_tag_name('a')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEB SCRAPING FINISHED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/sry46qbs59n25vtlyr3vfqrh0000gn/T/ipykernel_11884/1559815854.py:15: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  pageText = pageDriver.find_element_by_xpath(\"/html/body\")\n"
     ]
    }
   ],
   "source": [
    "def getLink(pageDriver, baseUrl):\n",
    "    # Get all 'a-tags'\n",
    "    a_tags = driver.find_elements_by_tag_name('a')\n",
    "\n",
    "    # Get all urls on page\n",
    "    urls = [tag.get_attribute('href') for tag in a_tags]\n",
    "\n",
    "    #Only base url and all related urls\n",
    "    useful_urls = [url for url in urls if url and baseUrl in url]\n",
    "\n",
    "    return useful_urls\n",
    "\n",
    "def getText(pageDriver):\n",
    "    # Get textual content from 'body' html tag\n",
    "    pageText = pageDriver.find_element_by_xpath(\"/html/body\")\n",
    "    if not pageText:\n",
    "        return \"\"\n",
    "    # pageText is webElement, pageText.text returns texts\n",
    "    return pageText.text\n",
    "\n",
    "\n",
    "visited_urls = set()\n",
    "unvisited_urls = set()\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "# run Chrome tab without interface\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(executable_path=ChromeDriverManager().install(), options=options)\n",
    "\n",
    "baseUrl = input(\"Please enter url of website: \")\n",
    "# Add base url to unvisited\n",
    "unvisited_urls.add(baseUrl)\n",
    "\n",
    "# counter for text indexing\n",
    "ct = 31963\n",
    "while unvisited_urls:\n",
    "    # Pop url from unvisited url set and add it to visited\n",
    "    page = unvisited_urls.pop()\n",
    "    visited_urls.add(page)\n",
    "\n",
    "    # Get page content\n",
    "    driver.get(page)\n",
    "\n",
    "    # Get links\n",
    "    links = getLink(driver, baseUrl)\n",
    "\n",
    "    # Get text\n",
    "    text = getText(driver)\n",
    "    textToWrite = text.splitlines()\n",
    "    # Create .csv file\n",
    "    with open(f'testCSV.csv', 'w') as csvfile:\n",
    "        fieldnames = ['id', 'text']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        # Write to .csv file with index and text\n",
    "        for text in textToWrite:\n",
    "            writer.writerow({'id': ct, 'text': {text}})\n",
    "            ct += 1\n",
    "\n",
    "print(\"WEB SCRAPING FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw .csv data using Pandas Dataframe\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('testCSV.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF (term frequency-inverse document frequency) is a statistical measure that evaluates how relevant a word is to a document in a collection of documents.\n",
    "This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents.\n",
    "\n",
    "Ref: \n",
    "    https://monkeylearn.com/blog/what-is-tf-idf/#:~:text=TF%2DIDF%20(term%20frequency%2D,across%20a%20set%20of%20documents\n",
    "\n",
    "\n",
    "Doc:\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of words is a Natural Language Processing technique of text modelling. \n",
    "In technical terms, we can say that it is a method of feature extraction with text data.\n",
    "\n",
    "Ref: \n",
    "    https://www.mygreatlearning.com/blog/bag-of-words/\n",
    "\n",
    "\n",
    "Doc:\n",
    "    https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.\n",
    "\n",
    "Ref/Doc:\n",
    "    https://scikit-learn.org/stable/modules/svm.html#:~:text=Support%20vector%20machines%20(SVMs)%20are,than%20the%20number%20of%20samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/sry46qbs59n25vtlyr3vfqrh0000gn/T/ipykernel_11884/4265950438.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  allTexts = train.append(test, ignore_index=True, sort=False)\n"
     ]
    }
   ],
   "source": [
    "# Combine training data with test data\n",
    "allTexts = train.append(test, ignore_index=True, sort=False)\n",
    "\n",
    "# allTexts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_texts(text, pattern):\n",
    "    process = re.findall(pattern, text)\n",
    "    for i in process:\n",
    "        text = re.sub(i, '', text) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/sry46qbs59n25vtlyr3vfqrh0000gn/T/ipykernel_11884/4189919608.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  allTexts['tidy_text'] = allTexts['tidy_text'].str.replace(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>tidy_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32034</th>\n",
       "      <td>32035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Hatewatch'}</td>\n",
       "      <td>Hatewatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32035</th>\n",
       "      <td>32036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Intelligence Report'}</td>\n",
       "      <td>Intelligence Report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32036</th>\n",
       "      <td>32037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Publications'}</td>\n",
       "      <td>Publications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32037</th>\n",
       "      <td>32038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Law Enforcement'}</td>\n",
       "      <td>Law Enforcement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32038</th>\n",
       "      <td>32039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Activist Toolkits'}</td>\n",
       "      <td>Activist Toolkits</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                     text                tidy_text\n",
       "32034  32035    NaN            {'Hatewatch'}              Hatewatch  \n",
       "32035  32036    NaN  {'Intelligence Report'}    Intelligence Report  \n",
       "32036  32037    NaN         {'Publications'}           Publications  \n",
       "32037  32038    NaN      {'Law Enforcement'}        Law Enforcement  \n",
       "32038  32039    NaN    {'Activist Toolkits'}      Activist Toolkits  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean text \n",
    "\n",
    "# Add new column 'tidy_text'\n",
    "# Clean usernames\n",
    "allTexts['tidy_text'] = np.vectorize(clean_texts)(\n",
    "    allTexts['text'], \"@[\\w]*\") \n",
    "\n",
    "# Clean non-alphabets\n",
    "allTexts['tidy_text'] = allTexts['tidy_text'].str.replace(\n",
    "    \"[^a-zA-Z]\", \" \") \n",
    "\n",
    "allTexts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32034               [Hatewatch]\n",
       "32035    [Intelligence, Report]\n",
       "32036            [Publications]\n",
       "32037        [Law, Enforcement]\n",
       "32038      [Activist, Toolkits]\n",
       "Name: tidy_text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokenized_text = allTexts['tidy_text'].apply(lambda x: x.split())\n",
    "\n",
    "tokenized_text.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenized_text.apply(\n",
    "    lambda x: [lemmatizer.lemmatize(i) for i in x])  \n",
    "\n",
    "# Combine tokens back together\n",
    "for i in range(len(tokenized_text)):\n",
    "    tokenized_text[i] = ' '.join(tokenized_text[i])\n",
    "\n",
    "# Replace with lemmatized\n",
    "allTexts['tidy_text'] = tokenized_text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag Of Words Model\n",
    "bow_vectorizer = CountVectorizer(\n",
    "    max_df=0.90, \n",
    "    min_df=2, \n",
    "    max_features=6000, \n",
    "    stop_words='english'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction - Bag-of-Words [sklearn’s CountVectorizer] \n",
    "# Matrix dimensions change accordingly to test data size\n",
    "\n",
    "# bag-of-words feature matrix\n",
    "bow = bow_vectorizer.fit_transform(allTexts['tidy_text'])\n",
    "# bow.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting feature matrix into training and testing matrices\n",
    "train_bow = bow[:31962, :]\n",
    "test_bow = bow[31962:, :]\n",
    "\n",
    "# splitting data into training and validation set\n",
    "# xtrain_bow training dataset\n",
    "# xvalid_bow validation for training\n",
    "# ytrain label vector\n",
    "# yvalid validation label vector\n",
    "xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(train_bow, train['label'], test_size=0.1)\n",
    "\n",
    "# train_bow feature matrix\n",
    "# train['label'] label vector\n",
    "# random_state shuffles data before split into training and testing\n",
    "# test_size percentage of data gets tested on (0.9 training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/sry46qbs59n25vtlyr3vfqrh0000gn/T/ipykernel_11884/2532116876.py:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predNum = predNum.astype(np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6914153132250581"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BoW\n",
    "logReg.fit(xtrain_bow, ytrain)                     \n",
    "\n",
    "# predicting on the validation set\n",
    "pred = logReg.predict_proba(xvalid_bow)\n",
    "# if prediction is greater than or equal to 0.31 than 1 else 0\n",
    "predNum = pred[:, 1] >= 0.31\n",
    "predNum = predNum.astype(np.int)\n",
    "\n",
    "f1_score(yvalid, predNum)  # calculating f1 score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/sry46qbs59n25vtlyr3vfqrh0000gn/T/ipykernel_11884/3719177678.py:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_pred_int = test_pred_int.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "# Predict test data using the bow model and Logistic Regression\n",
    "\n",
    "test_pred = logReg.predict_proba(test_bow)\n",
    "test_pred_int = test_pred[:, 1] >= 0.31\n",
    "test_pred_int = test_pred_int.astype(np.int)\n",
    "test['label'] = test_pred_int\n",
    "submission = test[['id', 'label']]\n",
    "# writing data to a CSV file\n",
    "submission.to_csv('sub_lreg_bow.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/sry46qbs59n25vtlyr3vfqrh0000gn/T/ipykernel_11884/470810405.py:6: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  prediction_int = prediction.astype(np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.676923076923077"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel='rbf', random_state=0, gamma=0.14, C=11)\n",
    "\n",
    "svm.fit(xtrain_bow, ytrain)\n",
    "\n",
    "prediction = svm.predict(xvalid_bow)\n",
    "prediction_int = prediction.astype(np.int)\n",
    "\n",
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/sry46qbs59n25vtlyr3vfqrh0000gn/T/ipykernel_11884/352891496.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_pred_int = test_pred.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "# prediction on test set\n",
    "test_pred = svm.predict(test_bow)\n",
    "\n",
    "test_pred_int = test_pred.astype(np.int)\n",
    "test['label'] = test_pred_int\n",
    "\n",
    "submission = test[['id', 'label']]\n",
    "# writing data to a CSV file\n",
    "submission.to_csv('svmrbfbow.csv', index=False)\n",
    "\n",
    "print(\"End SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF freq\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=0.90, \n",
    "    min_df=2, \n",
    "    max_features=6000, \n",
    "    stop_words='english'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TF-IDF Features - Looks at frequency of occurence for terms/importance of the term\n",
    "\n",
    "# TF = (Number of times term t appears in a document)/(Number of terms in the document)\n",
    "# IDF = log(N/n), where, N is the number of documents and n is the number of documents a term t has appeared in.\n",
    "# \n",
    "# TF-IDF = TF*IDF\n",
    "\n",
    "# TF-IDF feature matrix\n",
    "tfidf = tfidf_vectorizer.fit_transform(allTexts['tidy_text'])\n",
    "# tfidf.get_shape()\n",
    "# print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf feature matrix\n",
    "train_tfidf = tfidf[:31962, :]\n",
    "test_tfidf = tfidf[31962:, :]\n",
    "\n",
    "\n",
    "# ytrain.index index of axis labels \n",
    "# extract label vectors from the feature matrix via matching index\n",
    "xtrain_tfidf = train_tfidf[ytrain.index]\n",
    "xvalid_tfidf = train_tfidf[yvalid.index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/sry46qbs59n25vtlyr3vfqrh0000gn/T/ipykernel_11884/1561877750.py:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  prediction_int = prediction_int.astype(np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6986899563318778"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg.fit(xtrain_tfidf, ytrain)                   # Train model\n",
    "\n",
    "prediction = logReg.predict_proba(xvalid_tfidf)    # Predict validation set\n",
    "prediction_int = prediction[:, 1] >= 0.2\n",
    "prediction_int = prediction_int.astype(np.int)\n",
    "\n",
    "f1_score(yvalid, prediction_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/sry46qbs59n25vtlyr3vfqrh0000gn/T/ipykernel_11884/1418068712.py:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_pred_int = test_pred_int.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "# Predict Test data using TD-IDF - Logistic regression\n",
    "\n",
    "test_pred = logReg.predict_proba(test_tfidf)\n",
    "test_pred_int = test_pred[:, 1] >= 0.3\n",
    "test_pred_int = test_pred_int.astype(np.int)\n",
    "test['label'] = test_pred_int\n",
    "submission = test[['id', 'label']]\n",
    "# writing data to a CSV file\n",
    "submission.to_csv('sub_lreg_td-idf.csv', index=False)\n",
    "\n",
    "# if '1' in svm.predict(test_tfidf):\n",
    "#     print(\"it is racist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model using SVM\n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# svm.fit(xtrain_bow, ytrain)        # Build using bow\n",
    "\n",
    "# svm.fit(xtrain_tfidf, ytrain)      # Build using TD-IDF\n",
    "\n",
    "# SVC()\n",
    "\n",
    "# submission = test[['id', 'label']]\n",
    "# # writing data to a CSV file\n",
    "# submission.to_csv('svmrbfbow.csv', index=False)\n",
    "\n",
    "# print(\"End SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/sry46qbs59n25vtlyr3vfqrh0000gn/T/ipykernel_11884/2208432941.py:6: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  prediction_int = prediction.astype(np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7076167076167076"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "svm = SVC(kernel='rbf', random_state=0, gamma=0.14, C=11)\n",
    "\n",
    "svm.fit(xtrain_tfidf, ytrain) \n",
    "\n",
    "prediction = svm.predict(xvalid_tfidf)\n",
    "prediction_int = prediction.astype(np.int)\n",
    "\n",
    "f1_score(yvalid, prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/sry46qbs59n25vtlyr3vfqrh0000gn/T/ipykernel_11884/173282858.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_pred_int = test_pred.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "# prediction on test set\n",
    "test_pred = svm.predict(test_tfidf)\n",
    "test_pred_int = test_pred.astype(np.int)\n",
    "test['label'] = test_pred_int\n",
    "\n",
    "print(test_pred_int)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
